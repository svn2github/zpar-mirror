\documentclass[12pt]{article}
\usepackage[latin1]{inputenc}
\usepackage{graphicx}
\usepackage{makeidx}
\usepackage{hyperref}
\usepackage{CJK}
\usepackage{times}
\makeindex
\title{Phrase-Structure Parsing}
\begin{document}
\begin{CJK}{GBK}{song}
\maketitle

\section{How to compile}
Suppose that Zpar has been downloaded to the directory \textit{zpar}. To make a phrase-structure parsing system for English, type \textit{make english.conparser}. This will create a directory \textit{zpar/dist/english.conparser}, in which there are two files: \textit{train} and \textit{conparser}. The file \textit{train} is used to train a parsing model,and the file \textit{conparser} is used to parse new texts using a trained parsing model. Similarly, we can make a phrase-structure parsing system for Chinese by typing \textit{make chinese.conparser}. The \textit{train} and \textit{conparser} files are created under the directory of \textit{zpar/dist/chinese.conparser}. Note that the English and Chinese parsers are designed specifically for \href{http://www.cis.upenn.edu/~treebank/}{Penn Treebanks}.
\section{Format of inputs and outputs}
The input file to the \textit{train} file contains a set of parse trees, one for each line. An example parse tree is:
\begin{tabular}{l}
( S r ( NP r ( NNP t Ms. )  ( NNP t Haag )  )  ( S l* ( VP l ( VBZ t plays )  ( NP s ( NNP t Elianti )  )  )  ( . t . )  )  )\\
\end{tabular}
The format is different from the original format used in Penn Treebanks. Here is a \href{con_files/binarize.py}{Python script} to convert the original Penn Treebank format to the Zpar format. The usage is
\begin{tabular}{l}
python binarize.py $<$rule-file$>$ $<$input-file$>$ \\
\end{tabular}
Here \textit{rule-file} is a file containing head-finding rules (see the \href{con_files/rule.txt}{example rules} for Penn Chinese Treebank), and the conversion results will be printed to the console. Note that, in the respect of Chinese, the encoding of input-file to \textit{binarize.py} should be \textit{gb} and the output will be encoded in \textit{utf8}. Here is a \href{seg_files/gb2utf.py}{script} that transfers files that are encoded in \textit{gb} to the \textit{utf8} encoding.
\\
\\
The input file to the \textit{conparser} contain POS tagged sentences. The formats for English and Chinese are different.
\begin{tabular}{l}
\textbf{English}: \\
Ms./NNP Haag/NNP plays/VBZ Elianti/NNP\\
\textbf{Chinese}: \\
ZPar$\_$NR 可以$\_$MD 分析$\_$VV 中文$\_$NN 和$\_$CC 英文$\_$NN \\
\end{tabular}
For Chinese, inputs to both \textit{train} and \textit{conparser} must be encoded in \textit{utf8}.
\section{How to train a model}
To train a model, use
\begin{tabular}{l}
zpar/dist/english.conparser/train $<$train-file$>$ $<$model-file$>$ $<$number of iterations$>$ \\
\end{tabular}
For example, using the \href{con_files/train.txt}{train file}, you can train a  model by
\begin{tabular}{l}
zpar/dist/english.conparser/train train.txt model 1 \\
\end{tabular}
After training is completed, a new file \textit{model} will be created in the current directory, which can be used to parse POS-tagged sentences. The above command performs training with one iteration using the training file. The commands for training Chinese parsing models are the same.
\section{How to parse new texts}
To apply an existing model to parse new texts, use
\begin{tabular}{l}
zpar/dist/english.conparser/conparser $<$model$>$ $<$input-file$>$ $<$output-file$>$ \\
\end{tabular}
For example, using the model we just trained, we can parse \href{con_files/input.txt}{an example input} by
\begin{tabular}{l}
zpar/dist/english.conparser/conparser model input.txt output.txt \\
\end{tabular}
The output file contains automatically parsed trees. The commands for parsing Chinese texts are the same.
\section{Outputs and evaluation}
In order to evaluate the quality of the outputs, we can manually specify the gold parse trees of a sample, and compare the outputs with the correct sample.
\\
Manually specified parse trees of the input file are given in \href{con_files/reference.txt}{reference file}. Refer to \href{http://nlp.cs.nyu.edu/evalb/}{evalb} to obtain a software that performs automatic evaluation.
\\
Using the above \textit{output.txt} and \textit{reference.txt}, we can evaluate the accuracies by typing
\begin{tabular}{l}
./evalb -p $<$config.file$>$ output.txt reference.txt \\
\end{tabular}
Here \textit{config.file} sets running parameters of the evaluation. \href{con_files/COLLINS.prm}{COLLINS.prm} is a widely used configuration file.
Evaluation results will be printed to the console.
\section{How to tune the performance of a system}
The performance of the system after one training iteration may not be optimal. You can try training a model for another few iterations, after each you compare the performance. You can choose the model that gives the highest f-score on your test data. We conventionally call this test file the development test data, because you develop a parsing model using this. Here is a \href{con_files/test.sh}{a shell script} that automatically trains the parser for 30 iterations, and after the $i$th iteration, stores the model file to model.$i$. You can compare the f-score of all 30 iterations and choose model.$k$, which gives the best f-score, as the final model. In this file, this is a variable called \textit{parser}. You need to set this variable to the relative directory of \textit{zpar/dist/english.conparsr} or \textit{zpar/dist/chinese.conparser}.
\end{CJK}
\end{document}
